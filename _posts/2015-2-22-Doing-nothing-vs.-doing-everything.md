---
layout: post
title: Doing nothing vs. doing everything
category: teaching
---

There are two ends to the instructional design spectrum:

* doing nothing
* doing everything.

Let’s take a closer look.

## Doing nothing
Regardless of whether or not a new product, process, or policy is easy to learn you can always just leave learners (a.k.a. users, team members, customers, etc) to figure it out on their own. Here’s how:

Do nothing.
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>

Now this might work. However, people often have some questions they need answering when they are learning something new. If something is too complicated they will probably get frustrated and give up. Also, if they make a mistake it could cause big problems and cost big money.

Doing nothing probably isn’t the best option a lot of the time. This approach relies on learners being motivated and confident enough to figure things out on their own. They have to be patient, actually have the time to experiment, and can’t be afraid of failure.

Doing nothing might work if your goal is to teach people how to search the internet for ‘funny cat videos’. This is because:

* Google Search is super easy - you just type
* If you’re searching for 'funny cat videos' you definitely have lots of time on your hands.
* Also, very little can go wrong if you fail (other than your Facebook page won’t be quite as exciting).

So what’s at the other end of the instructional design spectrum?

## Doing everything

With all the problems and risks associated with *doing nothing*, maybe the best approach is to just do absolutely everything. Here’s what that looks like:

* Sending lots of emails with key information
* Designing lots of PowerPoint slides with plenty of bullet points
* Booking all your learners into full-day, face-to-face workshops
* Running webinars to reinforce the workshops
* Putting all the rules and instructions in elearning modules, and putting the elearning modules on your LMS
* Adding quizzes to test people on their knowledge of the rules and instructions
* Identifying the top 50 frequently asked questions and putting them into an FAQs resource
* Making all the business process maps available on a shared drive

All of these activities make it virtually impossible for learners to say, “I didn’t know what to do.” Which seems like a good thing.

Here’s what’s wrong with the *doing everything* approach: it’s almost always based on untested assumptions. Here are just a few of those assumptions:

* no learners have prior experience with this topic
* no learners can figure even part of this thing out on their own
* if something is complex then the only way to learn it is in a face-to-face workshop
* beginners often need more information so we better give them all the information just in case
* the more frequently asked questions the better
* business analysts aren’t the only ones that read the process maps they create
* most learners read, save, and refer back to important emails (and have an efficient system for doing so)

Now some of those assumptions may actually be correct. But think about your last project. How much time did you spend validating that email is an effective communication method? How did you validate this? What data did you collect? What about any of the other assumptions above? By validating, I don’t mean asking a manager. You actually need to talk to real learners, and observe what they normally do. Managers are busy and often only have time to give you the status quo response. In that case you then end up designing something that just meets the status quo.

In the event that one of the above is not correct, then the *doing everything* approach will result in wasted time and budget designing things that either won’t be used and/or won’t work.

## So what’s the answer?

Yes beginners will always need some FAQs answering. They may need to spend some time talking with an expert. Webinars are super popular these days. This means that the *do nothing* approach to instructional design will rarely be the best one. However, jumping straight to the opposite end of the spectrum isn’t the right choice either. Instead it’s about finding middle ground.

The best way to do this is to start by asking, “What if we did nothing?” knowing full well that this won’t be appropriate. But then you should imagine that you’re an inch worm and take teeny, tiny steps from *doing nothing* towards the other end of the spectrum. You do this by validating and testing every assumption starting with the most time consuming and expensive solutions.

Your focus should be to design the absolute minimum viable solution, one that will meet the needs of the majority of your learners. For example, the results of your learner research might be that although a new CRM system is being rolled out, learners have experience using it’s core features because they have used CRMs before. This may mean a quick reference guide and some videos of how to use the CRM are all that you need. Again, only interviewing and observing will tell you what solution will work best, not assumptions based on the way things have always been done.

## Take aways

* Don’t assume the *doing everything* approach is the right one.
* Validate your assumptions, especially if things have always been done a certain way.
* Start with *doing nothing* and only add what is absolutely necessary to design the minimum viable solution.
* Design less!
